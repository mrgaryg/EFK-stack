# Fluentd main configuration file
# Reference: https://docs.fluentd.org/v1.0/articles/config-file

# Set Fluentd to listen via http on port 8080, listening on all hosts
<system>
  # equal to -qq option
  log_level debug
</system>
<source>
  @type tail
  path /fluentd/demo_logs/**/*.log
  tag gtmlogs.*
  refresh_interval 2
  read_from_head true
  path_key tailed_path
  # <parse>
  #   @type none
  # </parse>
  <parse>
    @type multiline
    format_firstline /(^\w+).*(\d{2,4}-\d{1,2}-\d{1,2}\s\d{1,2}:\d{1,2}:\d{1,2},\d{1,3})(.*)/
    format1 /(?<level>^\w+).*(?<time>\d{2,4}-\d{1,2}-\d{1,2}\s\d{1,2}:\d{1,2}:\d{1,2},\d{1,3})(?<message>.*)/

    # match first word as one field and everything after it as a message
    # format1 /(?<level>^\w.*)\s\S(?<message>[\s\S]*)/
  </parse>
</source>

<filter gtmlogs.**>
  @type record_transformer
  <record>
    hostName ${tag_parts[3]}.${tag_parts[4]}.${tag_parts[5]}
  </record>
</filter>

<match gtmlogs.**>
  @type copy
  <store>
    @type elasticsearch
    host elasticsearch
    port 9200
    index_name gtmlogs
    type_name fluentd
    logstash_format true
    logstash_prefix gtmlogs
    logstash_dateformat %Y%m%d
    include_tag_key true
    tag_key @log_name
    flush_interval 1s
  </store>
  <store>
    @type file
    path /logs/gtmlogs
    flush_interval 10s
  </store>
</match>

# All other events will be printed to stdout
<match **>
  @type stdout
</match>